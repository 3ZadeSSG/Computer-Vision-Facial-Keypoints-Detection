"""
IMPORTANT : I have not written any exception handling here since this is just a prototype module.
            But exceptions can be logged into database with "traceback.format_exec()"
"""
import torch
import torch.nn as nn
import torch.nn.functional as F
import time
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
import cv2
import numpy as np
import torchvision
import traceback

# This python script will be called by Node.js as child process into project root directory, hence file paths will be from one level up.

HAAR_CASCADE_CHECKPOINT = "python_models/detector_architectures/haarcascade_frontalface_default.xml"
CNN_MODEL_CHECKPOINT = "python_models/saved_models/checkpoint.pth"
OUTPUT_PATH = "public/images/outputs/"



#=========================================================================
# Net Class which will create a CNN for generating keypoints.
#=========================================================================

class Net(nn.Module):

    def __init__(self):
        super(Net, self).__init__()

        self.conv1 = nn.Conv2d(1,32,5)
        # O/P = (224-5)/1 + 1 = 220, (32,220,220)

        self.pool1 = nn.MaxPool2d(2,2)
        # O/P = (W - F)/S + 1 = (220 - 2)/2 + 1 = (32,110,110)

        self.conv2 = nn.Conv2d(32,64,3)
        # O/P = (110-3)/1 + 1 = 108, (64,108,108)

        self.pool2 = nn.MaxPool2d(2,2)
        # O/P = (W - F)/S + 1 = (108 - 2)/2 + 1 = (64,54,54)

        self.conv3 = nn.Conv2d(64,128,3)
        # O/P = (54-3)/1 + 1 = 52, (64,52,52)

        self.pool3 = nn.MaxPool2d(2,2)
        # O/P = (W - F)/S + 1 = (52 - 2)/2 + 1 = (128,26,26)

        self.conv4 = nn.Conv2d(128,256,3)
        # O/P = (26-3)/1 + 1 = 24, (64,24,24)

        self.pool4 = nn.MaxPool2d(2,2)
        # O/P = (W - F)/S + 1 = (24 - 2)/2 + 1 = (256,12,12)

        self.fc1 = nn.Linear(256*12*12,1024)
        self.fc2 = nn.Linear(1024,512)
        self.fc3 = nn.Linear(512,136)

        self.conv1_drop = nn.Dropout(p = 0.5)
        self.conv2_drop = nn.Dropout(p = 0.4)
        self.conv3_drop = nn.Dropout(p = 0.3)
        self.conv4_drop = nn.Dropout(p = 0.2)

        self.fc1_drop = nn.Dropout(p = 0.4)
        self.fc2_drop = nn.Dropout(p = 0.2)


    def forward(self, x):

        x = self.conv1_drop(self.pool1(F.relu(self.conv1(x))))
        x = self.conv2_drop(self.pool2(F.relu(self.conv2(x))))
        x = self.conv3_drop(self.pool3(F.relu(self.conv3(x))))
        x = self.conv4_drop(self.pool4(F.relu(self.conv4(x))))

        x = x.view(x.size(0),-1)

        x = self.fc1_drop(F.relu(self.fc1(x)))
        x = self.fc2_drop(F.relu(self.fc2(x)))
        x = self.fc3(x)
        return x


#==================================================================
#   Load Checkpoint for given model from file location
#==================================================================

def loadCheckpoint(model, fileLocation):
    model.load_state_dict(torch.load(fileLocation))
    return model



def saveKeypoints(image, filename, keypoints = None, points_scale = 30, image_only = False):
    """ Plot keypoints on given numpy image and save it

    Arguments:
    #   image (numpy array): Image which needs to be plotted
    #   keypoints (numpy array): (64x2) co-ordinates (x,y) of facial keypoints which needs to be plotted on image (in purple color)
    #   keypoints_green (numpy array): (64x2) co-ordinates (x,y) of facial keypoints which needs to be plotted on image (in green color)

    """

    dpi = 80
    figsize = (image.shape[1]/dpi,image.shape[0]/dpi)
    fig = plt.figure(figsize = figsize)
    ax = fig.add_axes([0,0,1,1])
    ax.axis('off')

    ax.imshow(image, cmap="gray")
    if not image_only:
        ax.scatter(keypoints[:,0],keypoints[:,1], s = points_scale, marker=".",c="m")
    fig.savefig(OUTPUT_PATH + filename,dpi=dpi,transparent=True)
    plt.close(fig)

    return True


def getDetectedFaces(image_path):
    face_cascade = cv2.CascadeClassifier(HAAR_CASCADE_CHECKPOINT)
    img = cv2.imread(image_path)
    rgb_img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)
    gray_img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)
    detected_img = np.copy(rgb_img)
    faces = face_cascade.detectMultiScale(gray_img,1.5,5)
    for (x,y,w,h) in faces:
        detected_img = cv2.rectangle(detected_img,(x,y),(x+w,y+h),(255,0,0),2)
    return {"Original Image":rgb_img,
            "Gray Image":gray_img,
            "Detected Image":detected_img,
            "Faces":faces}


def regression_predict_keypoints(original_img, gray_img, points, model):
    """ Plots facial keypoints on selected square of gray image and also in orignal image

    Arguments:
    #   original_img (numpy array): Original RGB Image
    #   gray_img (numpy array): Gray Image generated from same original iamge
    #   points (numpy array): (x,y,w,h) for face box generated by open cv2 haar cascade
    #   save (boolean): Optional argument if original RGB image needs to be saved with plotted points
    #   filename (string): If image needs to be saved, filename of output image

    """

    gray_img_filename = "Gray_Plot_"+str(time.time())+".jpg"
    output_img_filename = "Output_Plot_"+str(time.time())+".jpg"

    x,y,w,h = points[0],points[1],points[2],points[3]

    gray_img = gray_img[y:y+h,x:x+w]

    # Will be used later to scale up points to original image
    original_square_size = gray_img.shape[0]
    #print(original_square_size)

    gray_img = gray_img/255
    gray_img = cv2.resize(gray_img, (224,224), interpolation = cv2.INTER_AREA)

    copied_gray_img = np.copy(gray_img)

    input_tensor = torchvision.transforms.ToTensor()(gray_img)
    input_tensor = input_tensor.unsqueeze(0)
    input_tensor = input_tensor.type(torch.FloatTensor)

    keypoints = model(input_tensor)

    keypoints = keypoints.view(68,2)
    keypoints = keypoints.data.numpy()
    keypoints = keypoints*50.0+100

    im = input_tensor.data
    im = im.numpy()
    im = np.transpose(im[0], (1, 2, 0))

    # this will plot image on selected square
    #(image, filename, keypoints = None, points_scale = 30, image_only = False)
    saveKeypoints(np.squeeze(im), gray_img_filename,  keypoints = keypoints)

    # to translate back the points to approx original image, we will use scaling factor
    # [[X_new],[Y_new]] = [[Sx,0],[0,Sy]] X [[X_old],[Y_old]]
    # X_Actual = X_new + x (here x is taken from (x,y,w,h) of haar cascade box)
    # Y_Actual = Y_new + y (here y is taken from (x,y,w,h) of haar cascade box)

    scale_ratio = original_square_size/224
    keypoints = keypoints*scale_ratio
    keypoints[:,0] = keypoints[:,0]+x
    keypoints[:,1] = keypoints[:,1]+y

    # if save argument is true then save the original image with keypoints plotted in it,
    # currently s = 100*scale_ration but it can me made bigger if original image is very high resolution
    # otherwise the dots will not be visible when plotted

    saveKeypoints(original_img, output_img_filename,  keypoints = keypoints, points_scale = 100*scale_ratio)
    return {"Gray_Plot":OUTPUT_PATH+gray_img_filename,"Output_Plot":OUTPUT_PATH+output_img_filename}


def detectKeypoints(filelocation):

    result = getDetectedFaces(filelocation)
    model = Net()
    model = loadCheckpoint(model, CNN_MODEL_CHECKPOINT)
    model.eval()
    outputList = []
    detected_faces_location = "Output_All_Faces_"+str(time.time())+".jpg"
    saveKeypoints(result["Detected Image"], detected_faces_location, image_only = True)

    for faces in result["Faces"]:
        outputList.append(regression_predict_keypoints(result["Original Image"],result["Gray Image"],faces,model))

    return {"All Detected Faces":OUTPUT_PATH+detected_faces_location,"Individual Mapping":outputList}





